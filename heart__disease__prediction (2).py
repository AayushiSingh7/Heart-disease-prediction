# -*- coding: utf-8 -*-
"""Heart _disease _prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O_W8DjiTf8HRCdSgfdoII6gScwivekSx

IMPORTING DEPENDENCIES
"""

#importing dependencies
import numpy as np  #create lists or arrays
import pandas as pd #create dataframes
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score # score to evaluate model

"""DATA COLLECTION AND PROCESSING"""

heart_data=pd.read_csv('/content/data.csv')

heart_data.head()

heart_data.tail()

#no. of rows and cols in dataset
heart_data.shape

#getting some info about the data
heart_data.info()

#checking missing values
heart_data.isnull().sum()

#statistical measures about the data
heart_data.describe()

#checking distribution of target variable
heart_data['target'].value_counts()

import seaborn as sb
import matplotlib.pyplot as plt

plt.figure(figsize=(13, 13))
sb.heatmap(heart_data.corr() > 0.9,
           annot=True,
           cbar=False)
plt.show()

"""1-->Defective heart

0-->Healthy heart

SPLITTING THE FEATURES AND TARGET
"""

#features in X and target in Y for further evaluation
X=heart_data.drop(columns='target',axis=1) #for dropping coloumn keep axis as 1 or for dropping a row then 0
Y=heart_data['target']

print(X)

print(Y)

"""Splitting the data into training and test data"""

X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=2)

print(X.shape,X_train.shape,X_test.shape)

"""MODEL TRAINING"""

# model=LogisticRegression()

# Normalizing the features for stable and fast training.
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

from sklearn.metrics import mean_absolute_error as mae
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

models = [
    LogisticRegression(),
    XGBClassifier(),
    DecisionTreeClassifier(),
    RandomForestClassifier(),
     KNeighborsClassifier()
]
#since dataset is balanced we use accuracy score for comparision
for i in range(5):
    models[i].fit(X_train, Y_train)

    print(f'{models[i]} : ')

    train_preds = models[i].predict(X_train)
    print('Training accuracy : ', accuracy_score(train_preds,Y_train))

    test_preds = models[i].predict(X_test)
    print('test accuracy : ', accuracy_score(test_preds,Y_test))
    print()

#training the logistic regression model with training data
# model.fit(X_train.values,Y_train.values) #try to find relationship between features and target

from sklearn.preprocessing import StandardScaler

from sklearn.pipeline import Pipeline

model = Pipeline([
    ('scaler', StandardScaler()),       # Scale the data
    ('logreg', LogisticRegression(max_iter=100))
])
model.fit(X_train, Y_train)

"""MODEL EVALUATION

ACCURACY SCORE
"""

#accuracy on training data
X_train_prediction=model.predict(X_train) #prediction based on trained model returns a list
training_data_accuracy=accuracy_score(X_train_prediction,Y_train)

print('Accuracy on training data:',training_data_accuracy)

#accuracy on test data
X_test_prediction=model.predict(X_test)
test_data_accuracy=accuracy_score(X_test_prediction,Y_test)
print('test data accuracy:',test_data_accuracy)

"""CONFUSION MATRIX"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay,accuracy_score, precision_score, recall_score, f1_score
#Compute the confusion matrix
cm = confusion_matrix(Y_test, X_test_prediction)
# Step 5: Visualize the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)
disp.plot(cmap='Blues')

accuracy = accuracy_score(Y_test, X_test_prediction)
preci = precision_score(Y_test, X_test_prediction)
recall = recall_score(Y_test, X_test_prediction)
f1 = f1_score(Y_test, X_test_prediction)

print(f"Accuracy: {accuracy:.2f}")
print(f"Precision: {preci:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1 Score: {f1:.2f}")

"""BUILDING A PREDICTIVE SYSTEM"""

input_data=(57,0,0,140,241,0,1,123,1,0.2,1,0,3)
feature_names = X_train.columns

# Create a DataFrame for input_data with the same feature names
input_data_df = pd.DataFrame([input_data], columns=feature_names)


# #change the data to a numpy array (to make it usable for prediction)
# input_data_as_numpy_array=np.asarray(input_data)

# #reshape the numpy array as we are predicting for only one instance
# input_data_reshaped=input_data_as_numpy_array.reshape(1,-1)
# prediction=model.predict(input_data_reshaped)


prediction=model.predict(input_data_df)
print(prediction)

if(prediction[0]==0):
  print('The person does not have a heart disease')
else:
  print('The person has heart disease')